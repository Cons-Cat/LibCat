// -*- mode: c++ -*-
// vim: set ft=cpp:
#pragma once

/* The Intel-style SIMD syntax is completely arbitrary in GCC. GNU implemented
 * it with wrapper libraries around their own more basic, arguably more
 * reasonable, compiler intrinsics which already understand arithmetic
 * operators, loads, sets, and many other common operations that Intel's wrap
 * inside a cumbersome interface. Then, authors of a SIMD wrapper library wrap
 * *those* wrappers with new ones to enhance their quality of life with features
 * that the basic compiler intrinsics largely already had. There are three
 * layers of technology to this for no reason!
 *
 * To streamline this, libCat uses the intrinsics which GNU already provides,
 * and wraps it in one thin layer of technology. */

#include <type_traits>

namespace std::detail {

// TODO: This comment is not currently accurate:
/* Vectors have weak alignment by default. It is up to users at call-site to
 * determine what alignment is appropriate for their use-case. All SIMD
 * functions are unaligned, which pays little, if any, penalty to aligned
 * vectors in modern implementations of SSE, AVX, and NEON architectures. */

template <typename T, isize Width>
struct alignas(4) SimdVector {
    static constexpr isize width = Width;
    using ScalarType = T;
    /* `vector_size` is a GCC attribute that represents SIMD data-types.
     * `using` and `alignas` do not work on a builtin vector type. Generalized
     * attribute syntax also does not appear to work. */
    typedef T  // NOLINT
        __attribute__((vector_size(sizeof(ScalarType) * Width), aligned(4)))
        IntrinsicType;
    IntrinsicType value;

    constexpr SimdVector() = default;
    // TODO: Perfect forwarding.
    constexpr SimdVector(IntrinsicType const& in_vector) {
        this->value = in_vector;
    }
    constexpr SimdVector(SimdVector<T, Width> const& operand) {
        this->value = operand.value;
    }
    // TODO: It would be nice to get this to work:
    // template <typename... UList>
    // constexpr simd_vector(UList... values) {
    //     this->value((static_cast<T>(values))...);
    // }

    // TODO: `__builtin_convertvector()` wrapped by conversion operators.

    constexpr auto operator=(SimdVector<T, Width> operand)
        -> SimdVector<T, Width>& {
        this->value = operand.value;
        return *this;
    }

    constexpr auto operator==(SimdVector<T, Width> const& operand)
        -> SimdVector<T, Width> {
        return SimdVector<T, Width>{.value = this->value == operand.value};
    }

    constexpr auto operator+(SimdVector<T, Width> operand)
        -> SimdVector<T, Width> {
        return SimdVector<T, Width>{this->value + operand.value};
    }
    constexpr auto operator+=(SimdVector<T, Width> const& operand)
        -> SimdVector<T, Width>& {
        this->value = this->value + operand.value;
        return *this;
    }

    constexpr auto operator-(SimdVector<T, Width> operand)
        -> SimdVector<T, Width> {
        return SimdVector<T, Width>{this->value - operand.value};
    }
    constexpr auto operator-=(SimdVector<T, Width> const& operand)
        -> SimdVector<T, Width>& {
        this->value = this->value - operand.value;
        return *this;
    }
};

}  // namespace std::detail

// Vectors of up to 32 1-byte integers are supported by AVX2.
using int1x2 = std::detail::SimdVector<int1, 2>;
using int1x4 = std::detail::SimdVector<int1, 4>;
using int1x8 = std::detail::SimdVector<int1, 8>;
using int1x16 = std::detail::SimdVector<int1, 16>;
using int1x32 = std::detail::SimdVector<int1, 32>;
using uint1x2 = std::detail::SimdVector<uint1, 2>;
using uint1x4 = std::detail::SimdVector<uint1, 4>;
using uint1x8 = std::detail::SimdVector<uint1, 8>;
using uint1x16 = std::detail::SimdVector<uint1, 16>;
using uint1x32 = std::detail::SimdVector<uint1, 32>;

/* Strings need their own vectors because uint1 and int1 are incompatible with
 * some intrinsic functions.*/
using charx2 = std::detail::SimdVector<char, 2>;
using charx4 = std::detail::SimdVector<char, 4>;
using charx8 = std::detail::SimdVector<char, 8>;
using charx16 = std::detail::SimdVector<char, 16>;
using charx32 = std::detail::SimdVector<char, 32>;

// Vectors of up to 16 2-byte integers are supported by AVX2.
using int2x2 = std::detail::SimdVector<int2, 2>;
using int2x4 = std::detail::SimdVector<int2, 4>;
using int2x8 = std::detail::SimdVector<int2, 8>;
using int2x16 = std::detail::SimdVector<int2, 16>;
using uint2x2 = std::detail::SimdVector<uint2, 2>;
using uint2x4 = std::detail::SimdVector<uint2, 4>;
using uint2x8 = std::detail::SimdVector<uint2, 8>;
using uint2x16 = std::detail::SimdVector<uint2, 16>;

// Vectors of up to 8 4-byte integers are supported by AVX2.
using int4x2 = std::detail::SimdVector<int4, 2>;
using int4x4 = std::detail::SimdVector<int4, 4>;
using int4x8 = std::detail::SimdVector<int4, 8>;
using uint4x2 = std::detail::SimdVector<uint4, 2>;
using uint4x4 = std::detail::SimdVector<uint4, 4>;
using uint4x8 = std::detail::SimdVector<uint4, 8>;

// Vectors of up to 4 8-byte integers are supported by AVX2.
using int8x2 = std::detail::SimdVector<int8, 2>;
using int8x4 = std::detail::SimdVector<int8, 4>;
using uint8x2 = std::detail::SimdVector<uint8, 2>;
using uint8x4 = std::detail::SimdVector<uint8, 4>;

// Vectors of up to 8 4-byte floats are supported by AVX2.
using float4x2 = std::detail::SimdVector<float4, 2>;
using float4x4 = std::detail::SimdVector<float4, 4>;
using float4x8 = std::detail::SimdVector<float4, 8>;

// TODO: Evaluate what support for 8-byte ints exists in x86-64.
//
// Vectors of up to 4 8-byte floats are supported by AVX2.
using float8x2 = std::detail::SimdVector<float8, 2>;
using float8x4 = std::detail::SimdVector<float8, 4>;

// Vectors of up to 32 1-byte bools are supported by AVX2.
using bool1x2 = std::detail::SimdVector<bool1, 2>;
using bool1x4 = std::detail::SimdVector<bool1, 4>;
using bool1x8 = std::detail::SimdVector<bool1, 8>;
using bool1x16 = std::detail::SimdVector<bool1, 16>;
using bool1x32 = std::detail::SimdVector<bool1, 32>;

// Vectors of up to 16 2-byte bools are supported by AVX2.
using bool2x2 = std::detail::SimdVector<bool2, 2>;
using bool2x4 = std::detail::SimdVector<bool2, 4>;
using bool2x8 = std::detail::SimdVector<bool2, 8>;
using bool2x16 = std::detail::SimdVector<bool2, 16>;

// Vectors of up to 8 4-byte bools are supported by AVX2.
using bool4x2 = std::detail::SimdVector<bool4, 2>;
using bool4x4 = std::detail::SimdVector<bool4, 4>;
using bool4x8 = std::detail::SimdVector<bool4, 8>;

namespace simd {

enum VectorMask : uint1
{
    // Source data format.
    SIDD_UBYTE_OPS = 0x00,
    SIDD_UWORD_OPS = 0x01,
    SIDD_SBYTE_OPS = 0x02,
    SIDD_SWORD_OPS = 0x03,
    // Comparison operation.
    SIDD_CMP_EQUAL_ANY = 0x00,
    SIDD_CMP_RANGES = 0x04,
    SIDD_CMP_EQUAL_EACH = 0x08,
    SIDD_CMP_EQUAL_ORDERED = 0x0c,
    // Polarity.
    SIDD_POSITIVE_POLARITY = 0x00,
    SIDD_NEGATIVE_POLARITY = 0x10,
    SIDD_MASKED_POSITIVE_POLARITY = 0x20,
    SIDD_MASKED_NEGATIVE_POLARITY = 0x30,
    // Output selection in _mm_cmpXstri()
    SIDD_LEAST_SIGNIFICANT = 0x00,
    SIDD_MOST_SIGNIFICANT = 0x40,
    // Output selection in _mm_cmpXstrm ().
    SIDD_BIT_MASK = 0x00,
    SIDD_UNIT_MASK = 0x40,
};

template <typename T>
consteval auto set_zeros() -> T;

// TODO: Use a vector concept.
auto shuffle(auto in_vector, auto mask);

// TODO: Make this const-correct.
template <uint4 Width>
auto p_string_to_p_vector(meta::string auto p_string) {
    using U = std::detail::SimdVector<char, Width>;
    return meta::bit_cast<U*>(p_string);
}

template <uint1 Mask>
auto cmp_implicit_str_count(auto const& vector_1, auto const& vector_2) -> bool;

template <uint1 Mask>
auto cmp_implicit_str_i(auto const& vector_1, auto const& vector_2) -> int4;

// TODO: Add `simd::mfence` and `simd::lfence`.
void sfence();
void zero_avx_registers();
void zero_upper_avx_registers();

// Constants for prefetch.
enum MM_HINT
{
    // MM_HINT_ET is MM_HINT_T with set 3rd bit.
    MM_HINT_ET0 = 7,
    MM_HINT_ET1 = 6,
    MM_HINT_T0 = 3,
    MM_HINT_T1 = 2,
    MM_HINT_T2 = 1,
    MM_HINT_NTA = 0
};

// This will not compile as a function.
#define prefetch(p_source, hint) \
    { __builtin_prefetch((p_source), (hint)&0x4 >> 2, (hint)&0x3); }

template <typename T>
void stream_in(void* p_destination, T const* source);

template <typename T>
auto move_mask(T vector) -> int4 {
    if constexpr (sizeof(typename T::ScalarType) == 1) {
        return __builtin_ia32_pmovmskb256(
            meta::bit_cast<std::detail::SimdVector<char, vector.width>>(vector)
                .value);
    } else {
        // TODO: Support additional vector sizes.
        static_assert("BAD!");
    }
}

}  // namespace simd

/* TODO: __builtin_cpu_init()
 * must be called before these. */

auto is_mmx_supported() -> bool;
auto is_sse1_supported() -> bool;
auto is_sse2_supported() -> bool;
auto is_sse3_supported() -> bool;
auto is_ssse3_supported() -> bool;
auto is_sse4_1_supported() -> bool;
auto is_sse4_2_supported() -> bool;
auto is_avx_supported() -> bool;
auto is_avx2_supported() -> bool;
auto is_avx512f_supported() -> bool;
auto is_avx512vl_supported() -> bool;

#include "./implementations/cmp_implicit_str_c.tpp"
#include "./implementations/cmp_implicit_str_i.tpp"
#include "./implementations/set_zeros.tpp"
#include "./implementations/shuffle.tpp"
#include "./implementations/stream_in.tpp"
